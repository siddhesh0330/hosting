


# 2C
# Study Conditional frequency distributions

import nltk
nltk.download('brown')
from nltk.corpus import brown
genre_word = [
(genre, word)
for genre in ['news', 'romance']
for word in brown.words(categories=genre)
]
print('Length of the Genre word is ', len(genre_word))
print(genre_word[:4])
print(genre_word[-4:])



# C2) Study of tagged corpora with methods like tagged_sents, tagged_words.
import nltk
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('universal_tagset')
nltk.download('nps_chat')
nltk.download('treebank')
nltk.download('conll2000')
from nltk.tokenize import word_tokenize
text=word_tokenize("And now for something completely different")
nltk.pos_tag(text)
print("\nBrown corpus: ", nltk.corpus.brown.tagged_words())
print("\nUniversal tagset: ", nltk.corpus.brown.tagged_words(tagset='universal'))
print("\nNPS chat corpus: ", nltk.corpus.nps_chat.tagged_words())
print("\nCONLL2000 corpus: ", nltk.corpus.conll2000.tagged_words())
print("\nTreebank corpus: ", nltk.corpus.treebank.tagged_words())




